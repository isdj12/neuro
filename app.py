import streamlit as st
import torch
from torchvision import transforms, models
from PIL import Image
import numpy as np

# --- 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ---
MODEL_PATH = "meat_classifier.pth"
# –ö–ª–∞—Å—Å—ã –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –ø–æ—Ä—è–¥–∫–æ–º, –≤ –∫–æ—Ç–æ—Ä–æ–º –æ–Ω–∏ –±—ã–ª–∏ –≤ train_dataset
CLASSES = ['defective', 'non_defective'] 
# –í—ã –º–æ–∂–µ—Ç–µ —Å–¥–µ–ª–∞—Ç—å –∏—Ö –±–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω—ã–º–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
USER_CLASSES = ['ü•© –ò–°–ü–û–†–ß–ï–ù–ù–´–ô / –ù–ï–ì–û–î–ù–´–ô –ü–†–û–î–£–ö–¢', '‚úÖ –°–í–ï–ñ–ò–ô / –ì–û–î–ù–´–ô –ü–†–û–î–£–ö–¢']

@st.cache_resource # –ö—ç—à–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏, —á—Ç–æ–±—ã –æ–Ω–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–∞–ª–∞—Å—å –ø—Ä–∏ –∫–∞–∂–¥–æ–º –¥–µ–π—Å—Ç–≤–∏–∏
def load_checkpoint(filepath):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ —Ñ–∞–π–ª–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Ç–æ—á–∫–∏ (.pth)."""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Ç–æ—á–∫—É, –∏—Å–ø–æ–ª—å–∑—É—è CPU, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å –ø–∞–º—è—Ç—å—é GPU –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ
        checkpoint = torch.load(filepath, map_location=torch.device('cpu'), weights_only=False)
        
        # 1. –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É (ResNet-18)
        model = models.resnet18(weights=None)
        
        # 2. –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π
        model.fc = checkpoint['classifier']
        
        # 3. –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –≤–µ—Å–∞
        model.load_state_dict(checkpoint['model_state_dict'])
        
        model.eval() # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        return model
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª '{MODEL_PATH}' –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —ç—Ç–æ–π –∂–µ –ø–∞–ø–∫–µ.")
        return None

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
model = load_checkpoint(MODEL_PATH)


# --- 2. –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ---

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (–¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å valid_transforms –∏–∑ main.py)
test_transforms = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

def preprocess_and_predict(image_file, model, user_classes):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."""
    if model is None:
        return "–ú–æ–¥–µ–ª—å –Ω–µ–∞–∫—Ç–∏–≤–Ω–∞."
        
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image = Image.open(image_file).convert("RGB")
    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –±–∞—Ç—á–∞
    tensor_image = test_transforms(image).unsqueeze(0) 

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    with torch.no_grad():
        output = model(tensor_image)
        probabilities = torch.softmax(output, dim=1)
        
    # –í—ã–±–∏—Ä–∞–µ–º –∫–ª–∞—Å—Å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
    top_p, top_class = probabilities.topk(1, dim=1)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–º—è –∫–ª–∞—Å—Å–∞
    predicted_class_index = top_class.item()
    confidence = top_p.item() * 100
    
    return user_classes[predicted_class_index], confidence

# --- 3. –û—Å–Ω–æ–≤–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ Streamlit ---

st.title("ü•© –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–¥—É–∫—Ç–∞ (Defective/Non-Defective)")
st.caption(f"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±—É—á–µ–Ω –Ω–∞ {len(CLASSES)} –∫–ª–∞—Å—Å–∞—Ö —Å –ø–æ–º–æ—â—å—é ResNet-18.")
st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞, —á—Ç–æ–±—ã –Ω–µ–π—Ä–æ—Å–µ—Ç—å –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∞ –µ–≥–æ —Å–≤–µ–∂–µ—Å—Ç—å/–∫–∞—á–µ—Å—Ç–≤–æ.")

if model is None:
    st.warning("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å, –ø–æ–∫–∞ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Å–æ–ª—å.")
else:
    uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        st.image(uploaded_file, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_column_width=True)
        st.write("") 
        
        # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        if st.button('–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ'):
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:")
            
            with st.spinner('–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...'):
                result_class, confidence = preprocess_and_predict(uploaded_file, model, USER_CLASSES)
            
            # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if "–ò–°–ü–û–†–ß–ï–ù–ù–´–ô" in result_class:
                st.error(f"‚ö†Ô∏è **–ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø:** {result_class}")
            else:
                st.success(f"üéâ **–ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø:** {result_class}")
                
            st.info(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: **{confidence:.2f}%**")